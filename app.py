import os
import tempfile

# Mem0 ê¶Œí•œ ë¬¸ì œ í•´ê²°
os.environ['MEM0_CONFIG_DIR'] = '/tmp'
os.environ['HOME'] = '/tmp'
os.environ['XDG_DATA_HOME'] = '/tmp'
os.environ['XDG_CONFIG_HOME'] = '/tmp'

import streamlit as st
st.set_page_config(
    page_title="ê²½íƒœì˜ AI ë¹„êµ ë¹„ì„œ", 
    layout="wide",
    initial_sidebar_state="expanded"
)
import requests
import copy
import json
import os
import uuid
import time
from datetime import datetime

# ğŸ”¥ Mem0 ì„í¬íŠ¸ë¥¼ try-exceptë¡œ ê°ì‹¸ê¸° (ì¡°ìš©í•˜ê²Œ)
try:
    from mem0 import MemoryClient
    MEM0_AVAILABLE = True
except ImportError:
    MEM0_AVAILABLE = False

# ================== API í‚¤ ì„¤ì • (ì˜êµ¬ ì €ì¥) ==================
# í™˜ê²½ë³€ìˆ˜ API í‚¤ ë¹„í™œì„±í™” (ë³´ì•ˆìƒ ìœ„í—˜)
API_KEY = ""  # í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ì•ˆí•¨
MEM0_KEY = ""  # í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ì•ˆí•¨

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "user_openrouter_key" not in st.session_state:
    st.session_state.user_openrouter_key = ""
if "user_mem0_key" not in st.session_state:
    st.session_state.user_mem0_key = ""
if "keys_permanently_saved" not in st.session_state:
    st.session_state.keys_permanently_saved = False

# íŒŒì¼ ê¸°ë°˜ í‚¤ ì €ì¥/ë³µì› (ë” í™•ì‹¤í•œ ë°©ë²•)
KEY_FILE = "/tmp/saved_keys.json"

def save_keys_to_file(openrouter_key, mem0_key=""):
    """í‚¤ë¥¼ íŒŒì¼ì— ì €ì¥"""
    try:
        import json
        data = {
            "openrouter_key": openrouter_key,
            "mem0_key": mem0_key,
            "timestamp": time.time()
        }
        with open(KEY_FILE, "w") as f:
            json.dump(data, f)
        return True
    except:
        return False

def load_keys_from_file():
    """íŒŒì¼ì—ì„œ í‚¤ ë¡œë“œ"""
    try:
        import json
        if os.path.exists(KEY_FILE):
            with open(KEY_FILE, "r") as f:
                data = json.load(f)
            return data.get("openrouter_key", ""), data.get("mem0_key", "")
    except:
        pass
    return "", ""

# ì•± ì‹œì‘ ì‹œ ì €ì¥ëœ í‚¤ ìë™ ë¡œë“œ
if not st.session_state.user_openrouter_key:
    saved_or_key, saved_mem0_key = load_keys_from_file()
    if saved_or_key:
        st.session_state.user_openrouter_key = saved_or_key
        st.session_state.user_mem0_key = saved_mem0_key
        st.session_state.keys_permanently_saved = True

# í˜„ì¬ í‚¤ ìƒíƒœ í™•ì¸
current_openrouter_key = st.session_state.user_openrouter_key
current_mem0_key = st.session_state.user_mem0_key

if not current_openrouter_key:
    st.markdown("### ğŸ”‘ API í‚¤ ì„¤ì •")
    st.info("ğŸ’¡ **ë³´ì•ˆ**: ê°ìì˜ API í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ AIë¥¼ ì´ìš©í•˜ì„¸ìš”!")
    
    # ì €ì¥ëœ í‚¤ ê´€ë¦¬
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ“‚ ì €ì¥ëœ í‚¤ í™•ì¸"):
            saved_or, saved_mem0 = load_keys_from_file()
            if saved_or:
                st.success(f"âœ… ì €ì¥ëœ OpenRouter í‚¤: {saved_or[:8]}...")
                if saved_mem0:
                    st.success(f"âœ… ì €ì¥ëœ Mem0 í‚¤: {saved_mem0[:8]}...")
            else:
                st.warning("âŒ ì €ì¥ëœ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with col2:
        if st.button("ğŸ—‘ï¸ ì €ì¥ëœ í‚¤ ì‚­ì œ"):
            try:
                if os.path.exists(KEY_FILE):
                    os.remove(KEY_FILE)
                st.success("ğŸ—‘ï¸ ì €ì¥ëœ í‚¤ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
            except:
                st.error("ì‚­ì œ ì‹¤íŒ¨")
    
    remember_keys = st.checkbox("ğŸ’¾ API í‚¤ ì˜êµ¬ ì €ì¥ (ê¶Œì¥)", value=True, 
                               help="ì²´í¬í•˜ë©´ ë‹¤ìŒì— ì ‘ì†í•  ë•Œ ìë™ìœ¼ë¡œ ë¡œê·¸ì¸ë©ë‹ˆë‹¤.")
    
    with st.form("api_key_form"):
        st.markdown("#### ğŸš€ í•„ìˆ˜: OpenRouter (AI ëª¨ë¸)")
        st.info("ğŸ’° **ì˜ˆìƒ ë¹„ìš©**: ê°€ë²¼ìš´ ì‚¬ìš© ì‹œ ì›” $1-3 ì •ë„")
        openrouter_key = st.text_input("OpenRouter API í‚¤", type="password", help="https://openrouter.ai ì—ì„œ ë°œê¸‰")
        
        st.markdown("#### ğŸ§  ì„ íƒ: Mem0 (AI ê°œì¸í™”)")
        st.info("âœ¨ **ê¸°ëŠ¥**: AIê°€ ë‹¹ì‹ ì˜ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ê³  í•™ìŠµ | ğŸ’° **ë¬´ë£Œ í”Œëœ** ìˆìŒ")
        mem0_key = st.text_input("Mem0 API í‚¤ (ì„ íƒì‚¬í•­)", type="password", help="https://mem0.ai ì—ì„œ ë°œê¸‰ (ì—†ì–´ë„ ê¸°ë³¸ ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥)")
        
        submitted = st.form_submit_button("ğŸš€ ì‹œì‘í•˜ê¸°", use_container_width=True)
        
        if submitted:
            if openrouter_key:
                st.session_state.user_openrouter_key = openrouter_key
                st.session_state.user_mem0_key = mem0_key if mem0_key else ""
                
                if remember_keys:
                    if save_keys_to_file(openrouter_key, mem0_key):
                        st.session_state.keys_permanently_saved = True
                        st.success("ğŸ’¾ API í‚¤ê°€ ì˜êµ¬ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.warning("âš ï¸ í‚¤ ì €ì¥ì— ì‹¤íŒ¨í–ˆì§€ë§Œ ì´ë²ˆ ì„¸ì…˜ì—ì„œëŠ” ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                
                if mem0_key:
                    st.success("âœ… ëª¨ë“  API í‚¤ê°€ ì„¤ì •ë˜ì—ˆì–´ìš”! (ê°œì¸í™” ê¸°ëŠ¥ í¬í•¨)")
                else:
                    st.success("âœ… OpenRouter API í‚¤ê°€ ì„¤ì •ë˜ì—ˆì–´ìš”! (ê¸°ë³¸ ê¸°ëŠ¥)")
                    st.info("ğŸ’¡ ë‚˜ì¤‘ì— Mem0 í‚¤ë¥¼ ì¶”ê°€í•˜ë©´ AI ê°œì¸í™” ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”!")
                
                st.balloons()
                time.sleep(2)
                st.rerun()
            else:
                st.error("âŒ OpenRouter API í‚¤ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤!")
    
    # ê°€ì´ë“œ í‘œì‹œ
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        **ğŸ¤– OpenRouter ê°€ì… ë°©ë²•:**
        1. https://openrouter.ai ì ‘ì†
        2. ì´ë©”ì¼ë¡œ íšŒì›ê°€ì…
        3. Dashboard â†’ API Keys â†’ Create Key
        4. í‚¤ ë³µì‚¬í•´ì„œ ìœ„ì— ë¶™ì—¬ë„£ê¸°
        """)
    
    with col2:
        st.markdown("""
        **ğŸ§  Mem0 ê°€ì… ë°©ë²• (ì„ íƒ):**
        1. https://mem0.ai ì ‘ì†
        2. ì´ë©”ì¼ë¡œ íšŒì›ê°€ì…
        3. API Keys â†’ Generate Key
        4. í‚¤ ë³µì‚¬í•´ì„œ ìœ„ì— ë¶™ì—¬ë„£ê¸°
        """)
    
    st.stop()

# í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì • (ì„ì‹œ)
if current_openrouter_key:
    os.environ["OPENROUTER_API_KEY"] = current_openrouter_key
if current_mem0_key:
    os.environ["MEM0_API_KEY"] = current_mem0_key

SAVE_PATH = "chat_history.json"

@st.cache_data(ttl=60)  # 1ë¶„ë§ˆë‹¤ ê°±ì‹ 
def get_available_models():
    """OpenRouterì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì™€ì„œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜"""
    
    # ì¼ë‹¨ ê¸°ë³¸ ëª¨ë¸ë“¤ ì •ì˜ (ì•ˆì „ì¥ì¹˜)
    default_models = {
        "GPT-4o": ("GPT-4o", "openai/gpt-4o", True, "#f1f1f1", "left"),
        "Claude": ("Claude 3.5 Sonnet", "anthropic/claude-3.5-sonnet", True, "#ffe4e1", "right"),
        "Gemini": ("Gemini 2.0 Flash", "google/gemini-2.0-flash-exp", True, "#e6f7ff", "left"),
        "LLaMA": ("LLaMA 3.1 405B", "meta-llama/llama-3.1-405b-instruct", True, "#ede7f6", "right")
    }
    
    try:
        # OpenRouter APIì—ì„œ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        response = requests.get("https://openrouter.ai/api/v1/models", timeout=10)
        
        if response.status_code == 200:
            api_data = response.json()
            new_models = {}
            
            # API ì‘ë‹µì—ì„œ data ë°°ì—´ ê°€ì ¸ì˜¤ê¸°
            for model in api_data.get("data", []):
                model_id = model.get("id", "")
                model_name = model.get("name", "")
                
                if model_id and model_name:
                    # ì´ë¯¸ì§€ ì§€ì› ì—¬ë¶€ í™•ì¸
                    supports_vision = False
                    if "modalities" in model:
                        supports_vision = "image" in model.get("modalities", [])
                    else:
                        vision_keywords = ["vision", "gpt-4", "claude", "gemini"]
                        supports_vision = any(keyword in model_id.lower() for keyword in vision_keywords)
                    
                    # ìƒ‰ìƒê³¼ ìœ„ì¹˜ ë§¤í•‘
                    if "gpt" in model_id.lower() or "openai" in model_id.lower():
                        color, side = "#f1f1f1", "left"
                        brand = "GPT"
                    elif "claude" in model_id.lower() or "anthropic" in model_id.lower():
                        color, side = "#ffe4e1", "right"
                        brand = "Claude"
                    elif "gemini" in model_id.lower() or "google" in model_id.lower():
                        color, side = "#e6f7ff", "left"
                        brand = "Gemini"
                    elif "llama" in model_id.lower() or "meta" in model_id.lower():
                        color, side = "#ede7f6", "right"
                        brand = "LLaMA"
                    else:
                        color, side = "#f5f5f5", "left"
                        brand = "ê¸°íƒ€"
                    
                    # í‘œì‹œìš© ì´ë¦„ ìƒì„±
                    display_name = model_name
                    if len(model_name) > 30:
                        display_name = f"{brand} {model_id.split('/')[-1][:20]}"
                    
                    new_models[display_name] = (model_name, model_id, supports_vision, color, side)
            
            # ìƒˆë¡œìš´ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë°˜í™˜
            if new_models:
                new_models["ğŸ¤– ìë™ ì„ íƒ (OpenRouterê°€ ìµœì  AI ì„ íƒ)"] = ("OpenRouter Auto", "auto", True, "#e6ffe6", "center")
                return new_models
        
    except Exception as e:
        # ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
        if hasattr(st, 'warning'):
            st.warning("âš ï¸ ìµœì‹  ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        pass
    
    # ëª¨ë“  ê²ƒì´ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ëª¨ë¸ë“¤ ë°˜í™˜
    return default_models

# ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
models = get_available_models()

# ================== Mem0 ì´ˆê¸°í™” (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹) ==================
@st.cache_resource
def init_mem0():
    """Mem0 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)"""
    if not MEM0_AVAILABLE:
        return None
    
    mem0_key = os.environ.get("MEM0_API_KEY", "") or st.session_state.get("user_mem0_key", "")
    
    if not mem0_key:
        return None
        
    try:
        return MemoryClient(api_key=mem0_key)
    except Exception as e:
        return None

memory_client = init_mem0()

# ================== ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ ==================
def show_learning_notification(learning_type, content=""):
    """ì‹¤ì‹œê°„ í•™ìŠµ ì•Œë¦¼ í‘œì‹œ"""
    notifications = {
        "ai_preference": f"ğŸ¤– AI ì„ í˜¸ë„ ê¸°ë¡: {content}",
        "conversation": f"ğŸ’­ ëŒ€í™” ë‚´ìš© ì €ì¥: {content}",
        "preference": f"â¤ï¸ ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥: {content}",
    }
    
    message = notifications.get(learning_type, f"ğŸ§  ìƒˆë¡œìš´ ê¸°ë¡: {content}")
    st.toast(message, icon="ğŸ§ ")

# ================== Mem0 ê´€ë ¨ í•¨ìˆ˜ë“¤ ==================
def get_user_id():
    """ì‚¬ìš©ì ID ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°"""
    if "user_id" not in st.session_state:
        st.session_state.user_id = f"user_{uuid.uuid4().hex[:8]}"
    return st.session_state.user_id

def classify_question_type(question):
    """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜"""
    question_lower = question.lower()
    if any(keyword in question_lower for keyword in [
        "ì½”ë”©", "í”„ë¡œê·¸ë˜ë°", "ì½”ë“œ", "ê°œë°œ", "ë””ë²„ê·¸", "í•¨ìˆ˜", "ì•Œê³ ë¦¬ì¦˜", 
        "python", "javascript", "html", "css"
    ]):
        return "coding"
    elif any(keyword in question_lower for keyword in [
        "ì°½ì‘", "ì†Œì„¤", "ì‹œ", "ê¸€ì“°ê¸°", "ìŠ¤í† ë¦¬", "ì‹œë‚˜ë¦¬ì˜¤", "ì—ì„¸ì´"
    ]):
        return "creative"
    elif any(keyword in question_lower for keyword in [
        "ë¶„ì„", "ë°ì´í„°", "ì—°êµ¬", "ë…¼ë¬¸", "í†µê³„", "ì°¨íŠ¸", "ê·¸ë˜í”„"
    ]):
        return "analysis"
    elif any(keyword in question_lower for keyword in [
        "ë¹ ë¥¸", "ê°„ë‹¨", "ìš”ì•½", "ì§§ê²Œ", "í•œì¤„ë¡œ", "ê°„ëµí•˜ê²Œ"
    ]):
        return "quick"
    else:
        return "general"

def learn_ai_preference_with_feedback(user_id, question, selected_ai):
    """AI ì„ íƒ íŒ¨í„´ í•™ìŠµ"""
    if not memory_client:
        return
    
    try:
        question_type = classify_question_type(question)
        memory_content = f"ì‚¬ìš©ìëŠ” {question_type} ì§ˆë¬¸ì— ëŒ€í•´ {selected_ai} AIë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤."
        
        metadata = {
            "type": "ai_preference",
            "selected_ai": selected_ai,
        }
        
        result = memory_client.add(memory_content, user_id=user_id, metadata=metadata)
        
        if result:
            show_learning_notification("ai_preference", f"{question_type} â†’ {selected_ai}")
        
    except Exception:
        pass

def get_preferred_ai(user_id, question):
    """í•™ìŠµëœ ì„ í˜¸ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ AI ì¶”ì²œ"""
    if not memory_client:
        return None, "ë©”ëª¨ë¦¬ ë¹„í™œì„±í™”"
    
    try:
        question_type = classify_question_type(question)
        memories = memory_client.search(f"{question_type} AI ì„ í˜¸ë„", user_id=user_id, limit=10)
        
        if memories:
            ai_count = {}
            for memory in memories:
                metadata = memory.get('metadata', {})
                if metadata.get('type') == 'ai_preference' and metadata.get('question_type') == question_type:
                    ai_name = metadata.get('selected_ai', '')
                    ai_count[ai_name] = ai_count.get(ai_name, 0) + 1
            
            if ai_count:
                preferred_ai = max(ai_count, key=ai_count.get)
                return preferred_ai, f"ğŸ§  í•™ìŠµëœ ì„ í˜¸ë„ (ì‚¬ìš©íšŸìˆ˜: {ai_count[preferred_ai]}íšŒ)"
        
        return None, "í•™ìŠµ ë°ì´í„° ì—†ìŒ"
    except Exception:
        return None, "ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨"

def smart_ai_selection_with_memory(user_id, question):
    """ë˜‘ë˜‘í•œ AI ì„ íƒ"""
    
    # 1. Mem0ê°€ ìˆìœ¼ë©´ í•™ìŠµëœ ì„ í˜¸ë„ í™•ì¸
    if memory_client:
        preferred_ai, reason = get_preferred_ai(user_id, question)
        
        if preferred_ai and "claude" in preferred_ai:
            claude4_id = None
            for name, (_, model_id_check, _, _, _) in models.items():
                if "anthropic" in name.lower() and "sonnet 4" in name.lower():
                    claude4_id = model_id_check
                    break
            
            if claude4_id:
                return claude4_id, f"ğŸ§  {reason}"
    
    # 2. ê¸°ë³¸ ë¡œì§
    question_text = question.lower()
    claude4_id = None
    for name, (_, model_id_check, _, _, _) in models.items():
        if "anthropic" in name.lower() and "sonnet 4" in name.lower():
            claude4_id = model_id_check
            break
    
    if any(keyword in question_text for keyword in [
        "ì½”ë”©", "í”„ë¡œê·¸ë˜ë°", "ì½”ë“œ", "ê°œë°œ", "ë””ë²„ê·¸", "í•¨ìˆ˜", "ì•Œê³ ë¦¬ì¦˜"
    ]):
        selected_ai = claude4_id if claude4_id else "anthropic/claude-3.5-sonnet"
        reason = "ğŸ”§ ì½”ë”© ì „ë¬¸"
    elif any(keyword in question_text for keyword in [
        "ì°½ì‘", "ì†Œì„¤", "ì‹œ", "ê¸€ì“°ê¸°", "ìŠ¤í† ë¦¬", "ì‹œë‚˜ë¦¬ì˜¤", "ì—ì„¸ì´"
    ]):
        selected_ai = "openai/gpt-4o"
        reason = "âœï¸ ì°½ì‘ ì „ë¬¸"
    elif any(keyword in question_text for keyword in [
        "ë¶„ì„", "ë°ì´í„°", "ì—°êµ¬", "ë…¼ë¬¸", "í†µê³„", "ì°¨íŠ¸", "ê·¸ë˜í”„"
    ]):
        selected_ai = claude4_id if claude4_id else "anthropic/claude-3.5-sonnet"
        reason = "ğŸ“Š ë¶„ì„ ì „ë¬¸"
    elif any(keyword in question_text for keyword in [
        "ë¹ ë¥¸", "ê°„ë‹¨", "ìš”ì•½", "ì§§ê²Œ", "í•œì¤„ë¡œ", "ê°„ëµí•˜ê²Œ"
    ]):
        selected_ai = "google/gemini-2.0-flash-exp"
        reason = "âš¡ ë¹ ë¥¸ ì‘ë‹µ"
    else:
        selected_ai = claude4_id if claude4_id else "anthropic/claude-3.5-sonnet"
        reason = "ğŸ¤– ë²”ìš© ì‘ë‹µ"
    
    return selected_ai, reason

def store_conversation_memory_with_feedback(user_id, question, answer, ai_model):
    """ëŒ€í™” ë‚´ìš©ì„ ì¥ê¸° ê¸°ì–µì— ì €ì¥"""
    if not memory_client:
        return
    
    try:
        question_summary = question[:100] + "..." if len(question) > 100 else question
        answer_summary = answer[:150] + "..." if len(answer) > 150 else answer
        
        conversation_summary = f"Q: {question_summary} A: {answer_summary}"
        
        metadata = {
            "type": "conversation",
            "ai_model": ai_model,
        }
        
        result = memory_client.add(conversation_summary, user_id=user_id, metadata=metadata)
        
        if result:
            show_learning_notification("conversation", f"{ai_model}ì™€ì˜ ëŒ€í™”")
        
    except Exception:
        pass

def get_relevant_context(user_id, current_question, limit=3):
    """í˜„ì¬ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê³¼ê±° ëŒ€í™” ì°¾ê¸°"""
    if not memory_client:
        return ""
    
    try:
        memories = memory_client.search(current_question, user_id=user_id, limit=limit)
        
        if memories:
            context = "ğŸ§  **ê³¼ê±° ê´€ë ¨ ëŒ€í™”:**\n"
            for memory in memories:
                context += f"- {memory['memory'][:100]}...\n"
            return context + "\n"
        
        return ""
    except Exception:
        return ""

def learn_user_preferences_with_feedback(user_id, feedback_type, context):
    """ì‚¬ìš©ì ì„ í˜¸ë„ í•™ìŠµ"""
    if not memory_client:
        return
    
    try:
        preference_data = f"ì‚¬ìš©ì í”¼ë“œë°±: {feedback_type} - {context}"
        
        metadata = {
            "type": "preference",
            "feedback": feedback_type,
            "timestamp": time.time()
        }
        
        result = memory_client.add(preference_data, user_id=user_id, metadata=metadata)
        
        if result:
            feedback_msg = "ê¸ì •ì  í”¼ë“œë°±" if feedback_type == "like" else "ê°œì„  ìš”ì²­"
            show_learning_notification("preference", feedback_msg)
        
    except Exception as e:
        pass

def get_user_personality_profile(user_id):
    """ì‚¬ìš©ì ì„±ê²©/ì„ í˜¸ë„ í”„ë¡œí•„ ìƒì„±"""
    if not memory_client:
        return "ì¼ë°˜ì ì¸ ì‚¬ìš©ì"
    
    try:
        memories = memory_client.search("ì‚¬ìš©ì", user_id=user_id, limit=20)
        
        if len(memories) > 5:
            return "ê²½í—˜ì´ í’ë¶€í•œ ì‚¬ìš©ì (ë§ì¶¤í˜• ì‘ë‹µ ì œê³µ)"
        elif len(memories) > 2:
            return "í•™ìŠµ ì¤‘ì¸ ì‚¬ìš©ì (ì¹œì ˆí•œ ì„¤ëª… ì œê³µ)"
        else:
            return "ìƒˆë¡œìš´ ì‚¬ìš©ì (ê¸°ë³¸ ë„ì›€ë§ ì œê³µ)"
    except Exception:
        return "ì¼ë°˜ì ì¸ ì‚¬ìš©ì"

def get_all_memories(user_id, limit=50):
    """ì‚¬ìš©ìì˜ ëª¨ë“  ë©”ëª¨ë¦¬ ê°€ì ¸ì˜¤ê¸°"""
    if not memory_client:
        return []
    
    try:
        memories = memory_client.search("", user_id=user_id, limit=limit)
        return memories
    except Exception:
        return []

def get_memory_stats_with_cache(user_id):
    """ë©”ëª¨ë¦¬ í†µê³„ ì •ë³´"""
    if not memory_client:
        return {"total": 0, "conversation": 0, "ai_preference": 0, "preference": 0}
    
    try:
        memories = memory_client.search("ì‚¬ìš©ì", user_id=user_id, limit=50)
        
        stats = {
            "total": len(memories),
            "conversation": 0,
            "ai_preference": 0,
            "preference": 0
        }
        
        for memory in memories:
            try:
                memory_content = str(memory.get('memory', '')).lower()
                
                if 'aië¥¼ ì„ íƒ' in memory_content or 'ì„ í˜¸ë„' in memory_content:
                    stats['ai_preference'] += 1
                elif 'í”¼ë“œë°±' in memory_content:
                    stats['preference'] += 1
                else:
                    stats['conversation'] += 1
            except Exception:
                stats['conversation'] += 1
        
        return stats
        
    except Exception as e:
        return {"total": 0, "conversation": 0, "ai_preference": 0, "preference": 0}

# ================== API í—¤ë” ì„¤ì • ==================
def get_headers():
    """API í—¤ë” ìƒì„±"""
    api_key = os.environ.get("OPENROUTER_API_KEY", "")
    return {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

# ================== í¬ë ˆë”§ í‘œì‹œ ==================
@st.cache_data(ttl=300)  # 5ë¶„ê°„ ìºì‹œ
def get_credit_balance():
    try:
        res = requests.get("https://openrouter.ai/api/v1/auth/key", headers=get_headers(), timeout=3)
        if res.status_code == 200:
            data = res.json().get("data", {})
            usage = data.get("usage", 0)
            
            if isinstance(usage, (int, float)):
                return usage
            else:
                return "API ì‘ë‹µ ì˜¤ë¥˜"
        else:
            return f"HTTP {res.status_code}"
    except requests.exceptions.Timeout:
        return "ì—°ê²° ì‹œê°„ ì´ˆê³¼"
    except requests.exceptions.ConnectionError:
        return "ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨"
    except Exception as e:
        return "ì—°ê²° ë¶ˆê°€"

credit = get_credit_balance()

# í¬ë ˆë”§ ìƒíƒœì— ë”°ë¥¸ í‘œì‹œ
if isinstance(credit, (int, float)):
    if credit == 0:
        credit_display = f"ğŸ’³ í¬ë ˆë”§: ë¬´ë£Œ ì‚¬ìš© ì¤‘"
        credit_color = "#4CAF50"
    elif credit < 1:
        credit_display = f"ğŸ’³ ì‚¬ìš© í¬ë ˆë”§: ${credit:.3f}"
        credit_color = "#4CAF50"
    elif credit < 5:
        credit_display = f"ğŸ’³ ì‚¬ìš© í¬ë ˆë”§: ${credit:.2f}"
        credit_color = "#FF9800"
    else:
        credit_display = f"ğŸ’³ ì‚¬ìš© í¬ë ˆë”§: ${credit:.1f}"
        credit_color = "#F44336"
else:
    credit_display = f"ğŸ’³ í¬ë ˆë”§ í™•ì¸ ë¶ˆê°€"
    credit_color = "#9E9E9E"

memory_status = "ğŸ§  AI ê°œì¸í™” í™œì„±í™”" if memory_client else "ğŸ’» ê¸°ë³¸ ëª¨ë“œ"

# ================== ChatGPT ìŠ¤íƒ€ì¼ ==================
st.markdown("""
    <style>
        .stApp {
            background-color: #f9f9f9 !important;
        }
        
        .main .block-container {
            max-width: 900px !important;
            padding: 2rem 1rem 1rem 1rem !important;  /* ìƒë‹¨ íŒ¨ë”© ì¦ê°€ */
            background: transparent !important;
        }
        
        /* í—¤ë” ê°œì„  */
        .chat-header {
            background: white !important;
            padding: 1.5rem !important;
            border-radius: 12px !important;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08) !important;
            margin-bottom: 1rem !important;  /* ë§ˆì§„ ì¤„ì„ */
            text-align: center;
            border: 1px solid #e5e5e5 !important;
        }
        
        .chat-title {
            font-size: 28px;
            font-weight: 700;
            color: #202123;
            margin-bottom: 0.5rem;
        }
        
        .chat-subtitle {
            font-size: 14px;
            color: #6e6e80;
            font-weight: 400;
        }
        
        /* ì…ë ¥ ì˜ì—­ - ìƒˆ ëŒ€í™” ë²„íŠ¼ ì œê±° */
        .input-container {
            background: white;
            border-radius: 16px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
            border: 1px solid #e5e5e5;
        }
        
        .stMultiSelect > div > div {
            border: 2px solid #e5e5e5 !important;
            border-radius: 12px !important;
            background: white !important;
        }
        
        .stMultiSelect > div > div:focus-within {
            border-color: #10a37f !important;
            box-shadow: 0 0 0 3px rgba(16, 163, 127, 0.1) !important;
        }
        
        .stChatInputContainer {
            border: none !important;
            background: transparent !important;
        }
        
        .stChatInputContainer > div {
            background: white !important;
            border: 2px solid #e5e5e5 !important;
            border-radius: 16px !important;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08) !important;
            display: flex !important;
            align-items: center !important;  /* ìˆ˜ì§ ì¤‘ì•™ ì •ë ¬ */
        }
        
        .stChatInputContainer textarea {
            border: none !important;
            background: transparent !important;
            font-size: 16px !important;
            padding: 1rem 1.5rem !important;
            line-height: 1.5 !important;  /* í…ìŠ¤íŠ¸ ë¼ì¸ ë†’ì´ ì¡°ì • */
        }
        
        .stChatInputContainer textarea:focus {
            border-color: #10a37f !important;
            box-shadow: 0 0 0 3px rgba(16, 163, 127, 0.1) !important;
        }
        
        /* ë³´ë‚´ê¸° ë²„íŠ¼ ì •ë ¬ */
        .stChatInputContainer button {
            display: flex !important;
            align-items: center !important;
            justify-content: center !important;
            margin: 0.5rem !important;
        }
        
        .stTabs [data-baseweb="tab-list"] {
            background: white !important;
            border-radius: 12px !important;
            padding: 0.5rem !important;
            border: 1px solid #e5e5e5 !important;
            margin-bottom: 1.5rem !important;
        }
        
        .stTabs [data-baseweb="tab"] {
            background: transparent !important;
            border-radius: 8px !important;
            color: #6e6e80 !important;
            font-weight: 500 !important;
            padding: 0.75rem 1.5rem !important;
        }
        
        .stTabs [aria-selected="true"] {
            background: #10a37f !important;
            color: white !important;
            box-shadow: 0 2px 4px rgba(16, 163, 127, 0.2) !important;
        }
        
        /* ì‚¬ì´ë“œë°” ê°œì„  */
        .css-1d391kg {
            background: #f7f7f8 !important;
            border-right: 1px solid #e5e5e5 !important;
            padding: 0 !important;
        }
        
        /* ì„¹ì…˜ í—¤ë” */
        .sidebar-header {
            color: #374151;
            font-size: 13px;
            font-weight: 600;
            padding: 1rem 1rem 0.5rem 1rem;
            margin: 0;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        
        /* ë©”ë‰´ ì•„ì´í…œ - í¬ê¸° ì¤„ì„ */
        .sidebar-item {
            margin: 0 0.5rem 0.25rem 0.5rem;
            border-radius: 6px;
            overflow: hidden;
        }
        
        .sidebar-item .stButton > button {
            width: 100% !important;
            border: none !important;
            background: transparent !important;
            color: #374151 !important;
            text-align: left !important;
            padding: 0.5rem 0.75rem !important;  /* íŒ¨ë”© ì¤„ì„ */
            font-size: 13px !important;  /* í°íŠ¸ í¬ê¸° ì¤„ì„ */
            font-weight: 400 !important;
            border-radius: 6px !important;
            transition: all 0.15s ease !important;
            line-height: 1.2 !important;
        }
        
        .sidebar-item .stButton > button:hover {
            background: #e5e7eb !important;
            color: #111827 !important;
            transform: none !important;
            box-shadow: none !important;
        }
        
        /* ìƒˆ ì±„íŒ… ë²„íŠ¼ íŠ¹ë³„ ìŠ¤íƒ€ì¼ */
        .new-chat-btn .stButton > button {
            background: #f3f4f6 !important;
            border: 1px solid #d1d5db !important;
            font-weight: 500 !important;
            padding: 0.75rem 1rem !important;  /* ìƒˆ ì±„íŒ…ì€ ì¢€ ë” í¬ê²Œ */
        }
        
        .new-chat-btn .stButton > button:hover {
            background: #e5e7eb !important;
            border-color: #9ca3af !important;
        }
        
        /* ëŒ€í™” í•­ëª© íŠ¹ë³„ ìŠ¤íƒ€ì¼ */
        .chat-item {
            display: flex !important;
            align-items: center !important;
            padding: 0.5rem 0.5rem !important;
        }
        
        .chat-item .stButton > button {
            font-size: 12px !important;  /* ë” ì‘ê²Œ */
            padding: 0.4rem 0.6rem !important;  /* ë” ì‘ê²Œ */
            white-space: nowrap !important;
            overflow: hidden !important;
            text-overflow: ellipsis !important;
            max-width: 100% !important;
        }
        
        /* ì‚­ì œ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
        .delete-btn {
            width: 28px !important;
            height: 28px !important;
            padding: 0 !important;
            min-width: 28px !important;
            margin-left: 4px !important;
        }
        
        .delete-btn .stButton > button {
            width: 28px !important;
            height: 28px !important;
            padding: 0 !important;
            font-size: 12px !important;
            border-radius: 4px !important;
            background: transparent !important;
            color: #9ca3af !important;
        }
        
        .delete-btn .stButton > button:hover {
            background: #fee2e2 !important;
            color: #dc2626 !important;
        }
        
        /* ì§„í–‰ë„ ë°” */
        .progress-bar {
            background: #e5e7eb;
            height: 6px;
            border-radius: 3px;
            overflow: hidden;
            margin: 0.5rem 0;
        }
        
        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #10b981, #059669);
            transition: width 0.3s ease;
            border-radius: 3px;
        }
        
        /* ìƒíƒœ ì•„ì´ì½˜ */
        .status-icon {
            display: inline-block;
            width: 8px;
            height: 8px;
            border-radius: 50%;
            margin-right: 8px;
        }
        
        .status-active { background: #10b981; }
        .status-inactive { background: #9ca3af; }
        
        /* êµ¬ë¶„ì„  */
        .sidebar-divider {
            height: 1px;
            background: #e5e7eb;
            margin: 1rem 0;
        }
        
        /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
        .metric-mini {
            background: white;
            border: 1px solid #e5e7eb;
            border-radius: 6px;
            padding: 0.6rem;  /* íŒ¨ë”© ì¤„ì„ */
            margin: 0.25rem 0;
            text-align: center;
        }
        
        .metric-number {
            font-size: 18px;  /* í¬ê¸° ì¤„ì„ */
            font-weight: 700;
            color: #10b981;
            line-height: 1;
        }
        
        .metric-label {
            font-size: 10px;
            color: #6b7280;
            margin-top: 2px;
        }
        
        .stButton > button {
            border-radius: 8px !important;
            border: 1px solid #e5e5e5 !important;
            font-weight: 500 !important;
            transition: all 0.2s ease !important;
        }
        
        .stButton > button:hover {
            transform: translateY(-1px) !important;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1) !important;
        }
        
        @media (max-width: 768px) {
            .main .block-container {
                padding: 0.5rem !important;
            }
            
            .chat-header {
                padding: 0.5rem 0 !important;
            }
            
            .input-container {
                padding: 1rem !important;
            }
        }
    </style>
""", unsafe_allow_html=True)

# í—¤ë” ë¶€ë¶„ - ë” ì»´íŒ©íŠ¸í•˜ê²Œ
st.markdown(f"""
<div class="chat-header">
    <div class="chat-title">ğŸ¤– AI ë¹„êµ ë¹„ì„œ</div>
    <div class="chat-subtitle">
        <span style="color: {credit_color};">{credit_display}</span> â€¢ 
        <span style="color: #10a37f;">{memory_status}</span>
    </div>
</div>
""", unsafe_allow_html=True)

# ================== ì»´íŒ©íŠ¸í•œ í†µí•© ì˜ì—­ ==================

# ì•ˆì „í•œ ê¸°ë³¸ê°’ ì„¤ì •
available_models = list(models.keys())
safe_defaults = []

# ê¸°ë³¸ê°’ìœ¼ë¡œ ìë™ ì„ íƒì„ ìš°ì„  ì„¤ì •
for model_key in available_models:
    if "ìë™ ì„ íƒ" in model_key:
        safe_defaults = [model_key]
        break

# ìë™ ì„ íƒì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì§
if not safe_defaults:
    for model_key in available_models:
        if any(keyword in model_key.lower() for keyword in ["gpt", "claude"]):
            safe_defaults.append(model_key)
            if len(safe_defaults) >= 2:
                break
        if len(safe_defaults) >= 2:
            break

# ë§Œì•½ ì•„ë¬´ê²ƒë„ ëª» ì°¾ìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸ ì‚¬ìš©
if not safe_defaults and available_models:
    safe_defaults = [available_models[0]]

selected = st.multiselect(
    "ğŸ¤– AI ëª¨ë¸ ì„ íƒ", 
    available_models, 
    default=safe_defaults,
    help="ë¹„êµí•  AI ëª¨ë¸ ì„ íƒ",
    placeholder="AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”"
)

st.markdown('</div>', unsafe_allow_html=True)

if not selected:
    st.warning("âš ï¸ AI ëª¨ë¸ì„ ìµœì†Œ 1ê°œëŠ” ì„ íƒí•´ì£¼ì„¸ìš”!")
    st.stop()

user_input = st.chat_input("ğŸ’¬ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? (Shift+Enterë¡œ ì¤„ë°”ê¿ˆ)")

# ================== ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° ==================
def save_logs():
    try:
        with open(SAVE_PATH, "w", encoding="utf-8") as f:
            json.dump({
                "logs": st.session_state.logs[-50:],  # ìµœê·¼ 50ê°œë§Œ ì €ì¥
                "chat_log": {
                    key: value[-20:] if isinstance(value, list) else value  # ê° ëª¨ë¸ë‹¹ ìµœê·¼ 20ê°œë§Œ
                    for key, value in st.session_state.chat_log.items()
                }
            }, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.warning(f"âš ï¸ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")

def load_logs():
    if os.path.exists(SAVE_PATH):
        try:
            with open(SAVE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                st.session_state.logs = data.get("logs", [])
                st.session_state.chat_log = {
                    key: data.get("chat_log", {}).get(key, []) 
                    for key in models
                }
        except Exception:
            pass

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëª¨ë¸ ë³€ê²½ì— ëŒ€ì‘)
if "logs" not in st.session_state:
    st.session_state.logs = []
if "chat_log" not in st.session_state:
    st.session_state.chat_log = {}

# ìƒˆë¡œìš´ ëª¨ë¸ì´ ì¶”ê°€ë˜ì—ˆì„ ë•Œ ëŒ€ì‘
for key in models:
    if key not in st.session_state.chat_log:
        st.session_state.chat_log[key] = []
    
load_logs()

# ================== ì±„íŒ… ê±°í’ˆ ==================
def render_chat_bubble(name, content, side="left", color="#f1f1f1"):
    """ChatGPT ìŠ¤íƒ€ì¼ ì±„íŒ… ë²„ë¸”"""
    
    is_user = name == "ê²½íƒœ"
    
    if is_user:
        # ì‚¬ìš©ì ë©”ì‹œì§€ (ìš°ì¸¡)
        st.markdown(f"""
        <div style="display: flex; justify-content: flex-end; margin-bottom: 1rem;">
            <div style="background: linear-gradient(135deg, #10a37f, #0d8f6f); 
                        color: white; padding: 0.75rem 1rem; 
                        border-radius: 1rem 1rem 0.25rem 1rem;
                        max-width: 70%; font-size: 0.9rem; line-height: 1.4;">
                <strong style="font-size: 0.75rem; opacity: 0.9;">{name}</strong><br>
                {content}
            </div>
        </div>
        """, unsafe_allow_html=True)
    else:
        # AI ë©”ì‹œì§€ (ì¢Œì¸¡)
        st.markdown(f"""
        <div style="display: flex; justify-content: flex-start; margin-bottom: 1rem;">
            <div style="background: #f8f9fa; color: #2d3748; 
                        padding: 0.75rem 1rem; border-radius: 1rem 1rem 1rem 0.25rem;
                        max-width: 70%; font-size: 0.9rem; line-height: 1.4;
                        border: 1px solid #e2e8f0;">
                <strong style="color: #10a37f; font-size: 0.75rem;">{name}</strong><br>
                {content}
            </div>
        </div>
        """, unsafe_allow_html=True)

# ================== ì‘ë‹µ ìš”ì²­ ==================
if user_input and user_input.strip():
    user_id = get_user_id()
    
    # ê³¼ê±° ê´€ë ¨ ëŒ€í™” ê°€ì ¸ì˜¤ê¸°
    relevant_context = get_relevant_context(user_id, user_input) if memory_client else ""
    
    # ì‚¬ìš©ì í”„ë¡œí•„ í™•ì¸
    user_profile = get_user_personality_profile(user_id) if memory_client else "ì¼ë°˜ì ì¸ ì‚¬ìš©ì"
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, key in enumerate(selected):
        name, model_id, supports_image, color, side = models[key]
        
        progress_bar.progress((idx + 1) / len(selected))
        status_text.text(f"ğŸ¤– {name} ì‘ë‹µ ì¤‘...")
        
        try:
            messages = st.session_state.chat_log.get(key, []).copy()

            # ë©”ëª¨ë¦¬ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ (í† í° ì ˆì•½)
            enhanced_input = user_input.strip()
            if relevant_context and len(relevant_context) < 500:  # ë„ˆë¬´ ê¸´ ì»¨í…ìŠ¤íŠ¸ ë°©ì§€
                enhanced_input = f"{relevant_context}\n**í˜„ì¬ ì§ˆë¬¸:** {user_input.strip()}"

            messages.append(("user", enhanced_input))

            # API í˜¸ì¶œìš© í¬ë§·
            formatted_messages = []
            for role, content in messages[-8:]:  # ìµœê·¼ 8ê°œë§Œ
                formatted_messages.append({"role": role, "content": content})

            # ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = {
                "role": "system", 
                "content": f"""ë„ˆëŠ” í•­ìƒ ë°˜ë§ì„ ì“°ê³  ì¹œêµ¬ì²˜ëŸ¼ ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•´. ì¡´ëŒ“ë§ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆ!
ì‚¬ìš©ì í”„ë¡œí•„: {user_profile}
- ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ìˆ˜ì¤€ì˜ ì„¤ëª…ì„ ì œê³µí•´ì¤˜."""
            }
            
            # AI ì„ íƒ í•™ìŠµ
            if memory_client and model_id != "auto":
                learn_ai_preference_with_feedback(user_id, user_input, name)
            
            # ìë™ ë¼ìš°íŒ…
            if model_id == "auto":
                question_text = user_input.lower()
                
                # ë§¥ë½ì´ í•„ìš”í•œ í‚¤ì›Œë“œë“¤
                context_keywords = [
                    "ì´ê±°", "ê·¸ê±°", "ì €ê±°", "ì—¬ê¸°ì„œ", "ê±°ê¸°ì„œ", "ì´ê²ƒ", "ê·¸ê²ƒ", "ì €ê²ƒ",
                    "ìœ„ì—ì„œ", "ì•ì—ì„œ", "ì´ì „", "ë°©ê¸ˆ", "ì•„ê¹Œ", "ê³„ì†", "ë”", "ì¶”ê°€",
                    "ìˆ˜ì •", "ë°”ê¿”", "ê³ ì³", "ê°œì„ ", "this", "that", "here", "there",
                    "above", "previous", "continue", "more", "add", "modify", "fix"
                ]
                
                # ì´ì „ ëŒ€í™”ê°€ ìˆê³ , ë§¥ë½ì´ í•„ìš”í•œ ì§ˆë¬¸ì´ë©´
                has_previous_chat = bool(st.session_state.chat_log.get(key, []))
                needs_context = any(keyword in question_text for keyword in context_keywords)
                
                if has_previous_chat and needs_context:
                    # ë§¥ë½ ìœ ì§€
                    claude4_id = None
                    for name_check, (_, model_id_check, _, _, _) in models.items():
                        if "anthropic" in name_check.lower() and "sonnet 4" in name_check.lower():
                            claude4_id = model_id_check
                            break
                    selected_model = claude4_id if claude4_id else "anthropic/claude-3.5-sonnet"
                    auto_reason = "ğŸ”— ëŒ€í™” ë§¥ë½ ìœ ì§€"
                else:
                    # ìƒˆë¡œìš´ ì£¼ì œ â†’ ìŠ¤ë§ˆíŠ¸ AI ì„ íƒ
                    selected_model, auto_reason = smart_ai_selection_with_memory(user_id, user_input)
                
                body = {
                    "model": selected_model,
                    "messages": [system_prompt] + formatted_messages,
                    "max_tokens": 1500,
                    "temperature": 0.7,
                    "stream": False
                }
                
                status_text.text(f"ğŸ¯ ìë™ì„ íƒ: {auto_reason}")
                
            else:
                body = {
                    "model": model_id,
                    "messages": [system_prompt] + formatted_messages,
                    "max_tokens": 1500,
                    "temperature": 0.7,
                    "stream": False
                }

            # API ìš”ì²­
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=get_headers(),
                json=body,
                timeout=45
            )
            
            if response.status_code == 200:
                data = response.json()
                if "choices" in data and data["choices"]:
                    res_text = data["choices"][0]["message"]["content"]
                    
                    # ëª¨ë“  ì„±ê³µì ì¸ ëŒ€í™”ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
                    if memory_client:
                        store_conversation_memory_with_feedback(user_id, user_input, res_text, name)
                    
                    # ìë™ ì„ íƒì¼ ë•Œ ì‹¤ì œ ì‚¬ìš©ëœ ëª¨ë¸ í‘œì‹œ
                    if model_id == "auto":
                        used_model = data.get("model", "unknown")
                        model_name = used_model.split('/')[-1] if '/' in used_model else used_model
                        res_text = f"ğŸ¯ **OpenRouter ì„ íƒ**: {model_name}\n\n{res_text}"
                        
                        # ìë™ ì„ íƒëœ AIë„ ì„ í˜¸ë„ í•™ìŠµ
                        if memory_client:
                            learn_ai_preference_with_feedback(user_id, user_input, model_name)
                    
                    # ì„¸ì…˜ì— ì €ì¥
                    if key not in st.session_state.chat_log:
                        st.session_state.chat_log[key] = []
                    
                    st.session_state.chat_log[key].append(("user", user_input.strip()))
                    st.session_state.chat_log[key].append(("assistant", res_text))
                else:
                    st.error(f"âŒ {name}: ì‘ë‹µ ë°ì´í„° ì˜¤ë¥˜")
            else:
                st.error(f"âŒ {name}: HTTP {response.status_code}")
                
        except requests.exceptions.Timeout:
            st.error(f"âŒ {name}: ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
        except Exception as e:
            st.error(f"âŒ {name}: {str(e)[:100]}")
    
    progress_bar.progress(1.0)
    status_text.text("âœ… ëª¨ë“  ì‘ë‹µ ì™„ë£Œ!")
    time.sleep(1)
    progress_bar.empty()
    status_text.empty()
    
    save_logs()
    st.rerun()

# ================== ê²°ê³¼ í‘œì‹œ ==================
if any(st.session_state.chat_log.get(model, []) for model in selected):
    tab1, tab2 = st.tabs(["ğŸ’¬ ì „ì²´ ëŒ€í™”", "ğŸ“Š ì‘ë‹µ ë¹„êµ"])
    
    with tab1:
        # ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ì»¨í…Œì´ë„ˆ ì¶”ê°€
        st.markdown("""
        <style>
        .chat-container {
            max-height: 70vh;
            overflow-y: auto;
            padding-right: 10px;
        }
        .chat-container::-webkit-scrollbar {
            width: 6px;
        }
        .chat-container::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 3px;
        }
        .chat-container::-webkit-scrollbar-thumb {
            background: #c1c1c1;
            border-radius: 3px;
        }
        .chat-container::-webkit-scrollbar-thumb:hover {
            background: #a8a8a8;
        }
        </style>
        """, unsafe_allow_html=True)
        
        st.markdown('<div class="chat-container">', unsafe_allow_html=True)
        
        for key in selected:
            chat = st.session_state.chat_log.get(key, [])
            if chat:
                name, _, _, color, side = models[key]
                st.markdown(f"### ğŸ¤– {name}")
                
                for role, content in chat:
                    bubble_name = "ê²½íƒœ" if role == "user" else name
                    bubble_color = "#e8f5e8" if role == "user" else color
                    bubble_side = "left" if role == "user" else side
                    
                    if isinstance(content, list):
                        text_content = next((p.get("text", "") for p in content if isinstance(p, dict) and p.get("type") == "text"), str(content))
                    else:
                        text_content = str(content)
                    
                    render_chat_bubble(bubble_name, text_content, bubble_side, bubble_color)
                
                st.markdown("---")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    with tab2:
        # ì§ˆë¬¸ë³„ ì‘ë‹µ ë¹„êµ
        questions = {}
        
        for model in selected:
            chat = st.session_state.chat_log.get(model, [])
            for i in range(0, len(chat) - 1, 2):
                if (i + 1 < len(chat) and 
                    chat[i][0] == "user" and 
                    chat[i + 1][0] == "assistant"):
                    
                    user_msg = chat[i][1]
                    assistant_msg = chat[i + 1][1]
                    
                    # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    if isinstance(user_msg, list):
                        q_text = next((p.get("text", "") for p in user_msg if isinstance(p, dict) and p.get("type") == "text"), "")
                    else:
                        q_text = str(user_msg)
                    
                    if q_text.strip():
                        if q_text not in questions:
                            questions[q_text] = {}
                        questions[q_text][model] = str(assistant_msg)

        for question, answers in questions.items():
            st.markdown(f"### ğŸ“Œ **{question}**")
            
            cols = st.columns(len(selected))
            for col, model in zip(cols, selected):
                with col:
                    name = models[model][0]
                    st.markdown(f"**ğŸ¤– {name}**")
                    answer = answers.get(model, "âŒ ì‘ë‹µ ì—†ìŒ")
                    st.markdown(f"""
                        <div style='background: #fafafa; padding: 15px; border-radius: 10px; 
                                    border-left: 4px solid #4CAF50; min-height: 120px;
                                    font-size: 15px; line-height: 1.4; white-space: pre-wrap;'>
                            {answer}
                        </div>
                    """, unsafe_allow_html=True)
            
            st.markdown("<br>", unsafe_allow_html=True)

# ================== Claude ìŠ¤íƒ€ì¼ ì‚¬ì´ë“œë°” ==================
with st.sidebar:
    # 1. ì±„íŒ… ì„¹ì…˜
    st.markdown('<p class="sidebar-header">ì±„íŒ…</p>', unsafe_allow_html=True)
    
    # ìƒˆ ì±„íŒ… ë²„íŠ¼
    st.markdown('<div class="sidebar-item new-chat-btn">', unsafe_allow_html=True)
    if st.button("âœ¨ ìƒˆ ì±„íŒ…", key="sidebar_new_chat", use_container_width=True):
        # í˜„ì¬ ëŒ€í™” ì €ì¥
        if any(st.session_state.chat_log.get(model, []) for model in selected if model in st.session_state.chat_log):
            title = f"ëŒ€í™”_{time.strftime('%m/%d_%H:%M')}"
            for model in selected:
                chat = st.session_state.chat_log.get(model, [])
                for role, content in reversed(chat):
                    if role == "user":
                        if isinstance(content, list):
                            text = next((p.get("text", "") for p in content if isinstance(p, dict) and p.get("type") == "text"), "")
                        else:
                            text = str(content)
                        if text.strip():
                            title = text.strip()[:25] + ("..." if len(text.strip()) > 25 else "")
                            break
                if "ëŒ€í™”_" not in title:
                    break
            
            st.session_state.logs.append((title, copy.deepcopy(st.session_state.chat_log)))
            save_logs()
        
        # ì´ˆê¸°í™”
        st.session_state.chat_log = {key: [] for key in models}
        save_logs()
        st.rerun()
    st.markdown('</div>', unsafe_allow_html=True)
    
    # 2. AI í•™ìŠµ í˜„í™© ì„¹ì…˜
    if memory_client:
        st.markdown('<div class="sidebar-divider"></div>', unsafe_allow_html=True)
        st.markdown('<p class="sidebar-header">AI í•™ìŠµ í˜„í™©</p>', unsafe_allow_html=True)
        
        user_id = get_user_id()
        memory_stats = get_memory_stats_with_cache(user_id)
        personalization_score = min(100, memory_stats["total"] * 5)
        
        # ë¯¸ë‹ˆ ë©”íŠ¸ë¦­ ì¹´ë“œë“¤
        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"""
            <div class="metric-mini">
                <div class="metric-number">{memory_stats["conversation"]}</div>
                <div class="metric-label">ëŒ€í™”</div>
            </div>
            """, unsafe_allow_html=True)
            
        with col2:
            st.markdown(f"""
            <div class="metric-mini">
                <div class="metric-number">{memory_stats["total"]}</div>
                <div class="metric-label">ì´ ê¸°ë¡</div>
            </div>
            """, unsafe_allow_html=True)
        
        # ì§„í–‰ë„ ë°”
        progress_color = "#10b981" if personalization_score >= 70 else "#f59e0b" if personalization_score >= 30 else "#ef4444"
        st.markdown(f"""
        <div style="padding: 0 1rem;">
            <div style="font-size: 12px; color: #6b7280; margin-bottom: 4px;">
                ê°œì¸í™” {personalization_score}%
            </div>
            <div class="progress-bar">
                <div class="progress-fill" style="width: {personalization_score}%; background: {progress_color};"></div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # í”¼ë“œë°± ë²„íŠ¼ (ê°„ì†Œí™”)
        if any(st.session_state.chat_log.get(model, []) for model in models):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown('<div class="sidebar-item">', unsafe_allow_html=True)
                if st.button("ğŸ‘", key="sidebar_like", use_container_width=True, help="ì¢‹ì€ ì‘ë‹µ"):
                    learn_user_preferences_with_feedback(user_id, "like", "ìµœê·¼ ì‘ë‹µì— ë§Œì¡±")
                    st.toast("ğŸ‘ í”¼ë“œë°± ì €ì¥!", icon="âœ…")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="sidebar-item">', unsafe_allow_html=True)
                if st.button("ğŸ‘", key="sidebar_dislike", use_container_width=True, help="ì•„ì‰¬ìš´ ì‘ë‹µ"):
                    learn_user_preferences_with_feedback(user_id, "dislike", "ìµœê·¼ ì‘ë‹µì— ë¶ˆë§Œì¡±")
                    st.toast("ğŸ‘ í”¼ë“œë°± ì €ì¥!", icon="âœ…")
                st.markdown('</div>', unsafe_allow_html=True)
    
    # 3. ìµœê·¼ í•­ëª© ì„¹ì…˜ (ê°œì„ ë¨)
    st.markdown('<div class="sidebar-divider"></div>', unsafe_allow_html=True)
    st.markdown('<p class="sidebar-header">ìµœê·¼ í•­ëª©</p>', unsafe_allow_html=True)
    
    if st.session_state.logs:
        # ìµœê·¼ 5ê°œ ëŒ€í™” í‘œì‹œ (í¬ê¸° ê°œì„ )
        for i, (title, log) in enumerate(reversed(st.session_state.logs[-5:]), 1):
            idx = len(st.session_state.logs) - i
            
            # ëŒ€í™” í•­ëª© - ì •ë ¬ ê°œì„ 
            st.markdown('<div class="chat-item">', unsafe_allow_html=True)
            col1, col2 = st.columns([4, 1])
            
            with col1:
                st.markdown('<div class="sidebar-item">', unsafe_allow_html=True)
                # ì œëª© ê¸¸ì´ ì œí•œ
                display_title = title[:20] + "..." if len(title) > 20 else title
                if st.button(f"ğŸ’¬ {display_title}", key=f"load_{i}", use_container_width=True):
                    st.session_state.chat_log = copy.deepcopy(log)
                    save_logs()
                    st.rerun()
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="delete-btn">', unsafe_allow_html=True)
                if st.button("ğŸ—‘", key=f"del_{i}", help="ì‚­ì œ", use_container_width=True):
                    st.session_state.logs.pop(idx)
                    save_logs()
                    st.rerun()
                st.markdown('</div>', unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
        
        # ë”ë³´ê¸° (5ê°œ ì´ìƒì¼ ë•Œ)
        if len(st.session_state.logs) > 5:
            with st.expander(f"â‹¯ {len(st.session_state.logs) - 5}ê°œ ë”ë³´ê¸°", expanded=False):
                for i, (title, log) in enumerate(reversed(st.session_state.logs[:-5]), 6):
                    idx = len(st.session_state.logs) - i
                    
                    st.markdown('<div class="chat-item">', unsafe_allow_html=True)
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        display_title = title[:20] + "..." if len(title) > 20 else title
                        if st.button(f"ğŸ’¬ {display_title}", key=f"load_old_{i}", use_container_width=True):
                            st.session_state.chat_log = copy.deepcopy(log)
                            save_logs()
                            st.rerun()
                    with col2:
                        st.markdown('<div class="delete-btn">', unsafe_allow_html=True)
                        if st.button("ğŸ—‘", key=f"del_old_{i}", use_container_width=True):
                            st.session_state.logs.pop(idx)
                            save_logs()
                            st.rerun()
                        st.markdown('</div>', unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.markdown("""
        <div style="padding: 1rem; text-align: center; color: #9ca3af; font-size: 13px;">
            ì €ì¥ëœ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤
        </div>
        """, unsafe_allow_html=True)
    
    # 4. ì„¤ì • ì„¹ì…˜ (í•˜ë‹¨)
    st.markdown('<div class="sidebar-divider"></div>', unsafe_allow_html=True)
    st.markdown('<p class="sidebar-header">ì„¤ì •</p>', unsafe_allow_html=True)
    
    # API ìƒíƒœ (ì»´íŒ©íŠ¸)
    openrouter_status = "status-active" if current_openrouter_key else "status-inactive"
    mem0_status = "status-active" if memory_client else "status-inactive"
    
    st.markdown(f"""
    <div style="padding: 0 1rem; font-size: 12px; color: #6b7280;">
        <div style="margin-bottom: 0.5rem;">
            <span class="status-icon {openrouter_status}"></span>OpenRouter
        </div>
        <div>
            <span class="status-icon {mem0_status}"></span>Mem0 ê°œì¸í™”
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # ì„¤ì • ë²„íŠ¼ë“¤
    if st.session_state.get("user_openrouter_key") or st.session_state.get("user_mem0_key"):
        st.markdown('<div class="sidebar-item">', unsafe_allow_html=True)
        if st.button("âš™ï¸ API í‚¤ ì¬ì„¤ì •", key="reset_api", use_container_width=True):
            st.session_state.user_openrouter_key = ""
            st.session_state.user_mem0_key = ""
            st.markdown("""
            <script>
            localStorage.removeItem('openrouter_key');
            localStorage.removeItem('mem0_key');
            localStorage.removeItem('keys_saved');
            </script>
            """, unsafe_allow_html=True)
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)
    
    # ê³ ê¸‰ ì„¤ì • (ë©”ëª¨ë¦¬ê°€ ìˆì„ ë•Œë§Œ)
    if memory_client:
        st.markdown('<div class="sidebar-item">', unsafe_allow_html=True)
        if st.button("ğŸ—‘ï¸ ëª¨ë“  ê¸°ì–µ ì‚­ì œ", key="delete_memory", use_container_width=True):
            try:
                memories = get_all_memories(user_id)
                for memory in memories:
                    if memory.get('id'):
                        memory_client.delete(memory.get('id'))
                st.toast("ëª¨ë“  ê¸°ì–µì„ ì‚­ì œí–ˆì–´ìš”!", icon="âœ…")
                time.sleep(1)
                st.rerun()
            except Exception as e:
                st.error(f"ì‚­ì œ ì‹¤íŒ¨: {e}")
        st.markdown('</div>', unsafe_allow_html=True)
    
    # í•˜ë‹¨ ì •ë³´
    st.markdown("""
    <div style="padding: 1rem; text-align: center; color: #9ca3af; font-size: 11px; border-top: 1px solid #e5e7eb; margin-top: 1rem;">
        AI ë¹„êµ ë¹„ì„œ v1.0
    </div>
    """, unsafe_allow_html=True)
